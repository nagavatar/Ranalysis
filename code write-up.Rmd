---
title: "Data Clean-up and Scaling"
author: "Declan Hill"
date: "12/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "C:/Users/decla/Desktop/College/ST661/Project")
```
Requires Tidyverse and Lubridate packages
```{r, message = F, warning = F}
library(tidyverse)
library(lubridate)
```


Read in datasets for 2019 and 2020. 2020 data is only from 1st January to the 31st of October.
```{r}
ped19      <- read.csv("dcc-2019-pedestrian-footfall-count-jan-dec_14082020.csv")
ped20      <- read.csv("jan-oct-2020-ped-data.csv")
```

Note that 2019 data is measured in 15-minute intervals, as opposed to 1-hour intervals in 2020 data. To be comparable, 2019 data must be reduced to same interval length, as follows:
```{r}
pedcount19 <- ped19[, 2:24]

n      <- length(pedcount19[, 1])
I      <- seq(1, n, by = 4)
hourly <- c()
hour   <- function(x){
  for(i in I){
    hourly[i] <- sum(x[i:(i + 3)], na.rm = T)
    i         <- i + 4
  }
  hourly <- na.omit(hourly)
}

cumulcount <- as.data.frame(sapply(pedcount19, hour))
Time       <- ped19$Time
Timestamp  <- Time[which(str_detect(Time, ".*:00:..") == T)]
ped19cumul <- cbind(Timestamp, cumulcount)
```

2019 data now reduced to hourly intervals, with the appropriate rows of the date/time column reattached.
Next, the two datasets were merged into one data frame. This required changing some column names. It was also noted that two entries appeared to be missing (31st March 2019, at 1:00 am and 29th March 2020 at 1:00 am). This was established to be due to the switch over to Summer Time, when the clocks were shifted forward by one hour. Empty rows of data were created and appended to the data frame to account for this. The timestamp column was updated and subsequently altered to a POSIXlt format, with the time zone set to UTC, which ignores Daylight Savings.
```{r}
names(ped20)[] <- names(ped19cumul)
ped19_20       <- rbind(ped19cumul, ped20)

mar3119        <- c("31-03-2019 01:00:00", rep(NA, 23))
mar2920        <- c("29-03-2019 01:00:00", rep(NA, 23))
ped19_20       <- rbind(ped19_20[1:2137, ], mar3119, ped19_20[- (1:2137), ])
ped19_20       <- rbind(ped19_20[1:10873, ], mar2920, ped19_20[- (1:10873), ])

time                   <- ped19_20$Timestamp
Timestamp              <- as.POSIXlt(time, format = "%d-%m-%Y %H:%M:%S", tz = "UTC")
pedcount19_20          <- ped19_20[, 2:24]
chars                  <- sapply(pedcount19_20, is.character)             
pedcount19_20          <- pedcount19_20                              
pedcount19_20[, chars] <- as.data.frame(apply(pedcount19_20[, chars], 2, as.numeric))
ped19_20hourly         <- cbind(Timestamp, pedcount19_20)
```

A simple test shows that the missing hours have successfully been added.
```{r}
ped19cumul$Timestamp[2136:2139]
ped19_20hourly$Timestamp[2136:2139]
```
Combining both Dawson.Street and Dawson.Street.Replacement columns into one
```{r}
Dawson.St <- rowSums(ped19_20hourly[, c(10, 18)], na.rm = T)
ped19_20hourly <- cbind(ped19_20hourly[, c(1:9, 11:17, 19:24)], Dawson.St)
```

The following code takes the merged dataset and scales it up to show counts for full days, using a similar function to the one above, but slightly altered. The dataframe produced at the end shows the total counts for each day, with only dates in the first column.
```{r}
Date       <- seq(as.Date("2019-01-01"), as.Date("2020-10-31"), by = "days")
countdaily <- ped19_20hourly[, 2:23]


n      <- length(countdaily[, 1])
I      <- seq(1, n, by = 24)
daily  <- c()
day    <- function(x){
  for(i in I){
    x         <- replace_na(x, 0)
    daily[i]  <- sum(x[i:(i + 23)])
    i         <- i + 24
  }
  daily <- na.omit(daily)
}

cumulcount    <- as.data.frame(sapply(countdaily, day))
ped19_20daily <- cbind(Date, cumulcount)
```

The next function instead calculates the mean count for each day.
```{r}
n        <- length(countdaily[, 1])
I        <- seq(1, n, by = 24)
dailyavg <- c()
daym     <- function(x){
  for(i in I){
    x           <- replace_na(x, 0)
    dailyavg[i] <- mean(x[i:(i + 23)])
    i           <- i + 24
  }
  dailyavg <- na.omit(dailyavg)
}

means            <- as.data.frame(sapply(countdaily, daym))
ped19_20daymeans <- cbind(Date, means)
```

These functions do the same as above, but scale the data up again to weekly counts/ means
```{r}
WeekBeginning <- seq(as.Date("2019-01-01"), as.Date("2020-10-26"), by = "weeks")
countweekly   <- ped19_20daily[, 2:23]

n      <- length(countweekly[, 1])
I      <- seq(1, n, by = 7)
weekly <- c()
week   <- function(x){
  for(i in I){
    weekly[i] <- sum(x[i:(i + 6)])
    i         <- i + 7
  }
  weekly <- na.omit(weekly)
}

cumulcount     <- as.data.frame(sapply(countweekly, week))
ped19_20weekly <- cbind(WeekBeginning, cumulcount)
##  Last 5 days of Oct. 2020 omitted 
```

```{r}
n         <- length(countweekly[, 1])
I         <- seq(1, n, by = 7)
weeklyavg <- c()
weekm     <- function(x){
  for(i in I){
    x            <- replace_na(x, 0)
    weeklyavg[i] <- mean(x[i:(i + 6)])
    i            <- i + 7
  }
  weeklyavg <- na.omit(weeklyavg)
}

means             <- as.data.frame(sapply(countweekly, weekm))
ped19_20weekmeans <- cbind(WeekBeginning, means)
```

These graphs are simple comparisons of the daily average footfall on certain streets between January and October in 2019 and 2020 (November, December 2019 ommitted for fair comparison with 2020 data), as well as a graph of both years combined. Each street shows a clear change in the numbers of people, and in the patterns of footfall. There is some degree of normality to the data, and the two-year graphs clearly show distinct bimodality in the data for many streets.
```{r, fig.height = 4, fig.width = 12}
par(mfrow = c(1, 3))
hist(ped19_20daymeans$Dawson.St[1:304], main = "Dawson St. 2019", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Dawson.St[366:670], main = "Dawson St. 2020", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Dawson.St, main = "Dawson St. 2019 - 2020", ylab = "Avg. No. of Pedestrians")

hist(ped19_20daymeans$Henry.Street[1:304], main = "Henry St. 2019", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Henry.Street[366:670], main = "Henry St. 2020", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Henry.Street, main = "Henry St. 2019 - 2020", ylab = "Avg. No. of Pedestrians")

hist(ped19_20daymeans$College.Green..Bank.Of.Ireland[1:304], main = "College Green (BOI) 2019", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$College.Green..Bank.Of.Ireland[366:670], main = "College Green (BOI) 2020", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$College.Green..Bank.Of.Ireland, main = "College Green (BOI) 2019 - 2020", ylab = "Avg. No. of Pedestrians")

hist(ped19_20daymeans$Westmoreland.Street.East[1:304], main = "Westmoreland St. (E) 2019", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Westmoreland.Street.East[366:670], main = "Westmoreland St. (E) 2020", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Westmoreland.Street.East, main = "Westmoreland St. (E) 2019 - 2020", ylab = "Avg. No. of Pedestrians")

hist(ped19_20daymeans$Westmoreland.Street.West[1:304], main = "Westmoreland St. (W) 2019", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Westmoreland.Street.West[366:670], main = "Westmoreland St. (W) 2020", ylab = "Avg. No. of Pedestrians")
hist(ped19_20daymeans$Westmoreland.Street.West, main = "Westmoreland St. (W) 2019 - 2020", ylab = "Avg. No. of Pedestrians")
```
